{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK para procesamiento de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras = []\n",
    "books = []\n",
    "for i in range (1,7):\n",
    "    name = \"libro\"\n",
    "    name += str(i) + \".txt\"\n",
    "    with open(name) as libro:\n",
    "        temp = nltk.word_tokenize(libro.read().lower())\n",
    "        books.append(temp)\n",
    "    palabras += temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stoplist.txt') as file:\n",
    "    stoplist = [line.lower().strip() for line in file]\n",
    "stoplist += ['.','?','-',',',';','»','«','¿','¡','!',':','(',')','\\'\\'',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_books = books[:]\n",
    "\n",
    "for book in clean_books:\n",
    "    for token in book:\n",
    "        if token in stoplist:\n",
    "            book.remove(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduccion de palabras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "books_index = []\n",
    "for book in clean_books:\n",
    "    temp = []\n",
    "    for w in book:\n",
    "        temp.append(stemmer.stem(w))\n",
    "    books_index.append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construir el índice con los 500 términos más frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "frec = {}\n",
    "\n",
    "allwords = []\n",
    "\n",
    "for book in books_index:\n",
    "    for w in book:\n",
    "        allwords.append(w)\n",
    "        \n",
    "for w in allwords:\n",
    "   frec[w] = allwords.count(w)\n",
    "\n",
    "frec = sorted(frec.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "most_frec = []\n",
    "term = 0\n",
    "for w in enumerate(frec):\n",
    "    term += 1\n",
    "    if(term == 501):\n",
    "        break\n",
    "    most_frec.append(w[1][0])\n",
    "\n",
    "most_frec.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar el índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = {}\n",
    "\n",
    "for w in most_frec:\n",
    "    ind[w] = []\n",
    "\n",
    "#print(ind)\n",
    "n_book = 1\n",
    "for book in books_index:\n",
    "    for w in most_frec:\n",
    "        if w in book:\n",
    "            ind[w].append(n_book)\n",
    "    n_book+=1\n",
    "\n",
    "indexFile = open('index.txt','w')\n",
    "for i in ind.items():\n",
    "    indexFile.write(str(i))\n",
    "    indexFile.write('\\n')\n",
    "indexFile.close()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. APLICAR CONSULTAS BOOLEANAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n",
      "[2, 3]\n",
      "[1, 2, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "def L(token):\n",
    "    if ind.get(stemmer.stem(token).lower()) == None:\n",
    "        return []\n",
    "    else: \n",
    "        return ind.get(stemmer.stem(token).lower())\n",
    "\n",
    "print(L(\"Frodo\"))\n",
    "print(L(\"abismo\"))\n",
    "print(L(\"acompañar\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función ADD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def AND(books_1, books_2):\n",
    "    result = []\n",
    "    for i in books_1:\n",
    "        for j in books_2:\n",
    "            if i == j:\n",
    "                result.append(i)\n",
    "    return result\n",
    "\n",
    "#Ejemplo\n",
    "print(AND(L(\"Frodo\"), L(\"abismo\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def OR(books_1, books_2):\n",
    "    result = books_1 + books_2\n",
    "    result = list(set(result))\n",
    "    sorted(result)\n",
    "    return result\n",
    "\n",
    "print(OR(L(\"abismo\"), L(\"acaba\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "def AND_NOT(books_1, books_2):\n",
    "    for i in books_2:\n",
    "        if i in books_1:\n",
    "            books_1.remove(i)\n",
    "    sorted(books_1)\n",
    "    return books_1\n",
    "\n",
    "print(AND_NOT(L(\"Frodo\"), L(\"obra\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "result = AND_NOT(AND(L(\"Frodo\"), L(\"Abismo\")), L(\"acompañar\"))\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
